"""
–ú–æ–¥—É–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ PCAP —Ñ–∞–π–ª–æ–≤ –∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π –≤ —Å–µ—Ç–µ–≤–æ–º —Ç—Ä–∞—Ñ–∏–∫–µ.
"""

import pandas as pd
import os
import json
import html
from feature_extractor import extract_features_from_pcap
from anomaly_detector import AnomalyDetector


def _extract_flow_metadata(pcap_file):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø–æ—Ç–æ–∫–æ–≤ (IP –∞–¥—Ä–µ—Å–∞, timestamp) –∏–∑ PCAP —Ñ–∞–π–ª–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å, –≥–¥–µ –∫–ª—é—á - —ç—Ç–æ –∏–Ω–¥–µ–∫—Å –ø–æ—Ç–æ–∫–∞, –∞ –∑–Ω–∞—á–µ–Ω–∏–µ - –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ.
    """
    from scapy.all import rdpcap, IP, TCP, UDP, ICMP
    from collections import defaultdict
    from feature_extractor import _normalize_flow_key, _get_protocol_name, _get_ports
    
    packets = rdpcap(pcap_file)
    flows = defaultdict(lambda: {
        'packets': [],
        'timestamps': [],
        'src_ip': None,
        'dst_ip': None,
        'src_port': None,
        'dst_port': None,
        'protocol': None
    })
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –ø–∞–∫–µ—Ç
    for packet in packets:
        if not packet.haslayer(IP):
            continue
        
        ip_layer = packet[IP]
        src_ip = ip_layer.src
        dst_ip = ip_layer.dst
        
        protocol_name = _get_protocol_name(packet)
        src_port, dst_port = _get_ports(packet)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–ª—é—á –ø–æ—Ç–æ–∫–∞
        flow_key = _normalize_flow_key(src_ip, dst_ip, src_port, dst_port, protocol_name)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ—Ç–æ–∫–µ
        flow = flows[flow_key]
        flow['packets'].append(packet)
        flow['timestamps'].append(float(packet.time))
        flow['src_ip'] = flow_key[0]
        flow['dst_ip'] = flow_key[1]
        flow['src_port'] = flow_key[2]
        flow['dst_port'] = flow_key[3]
        flow['protocol'] = flow_key[4]
    
    # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ —Ç–æ–º –∂–µ –ø–æ—Ä—è–¥–∫–µ, —á—Ç–æ –∏ –ø—Ä–∏–∑–Ω–∞–∫–∏
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ—Ç–æ–∫–∏ –ø–æ –∫–ª—é—á—É –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏–∏ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞
    metadata_list = []
    sorted_flows = sorted(flows.items(), key=lambda x: x[0])
    
    for flow_key, flow_data in sorted_flows:
        if len(flow_data['packets']) == 0:
            continue
        
        start_time = min(flow_data['timestamps'])
        metadata_list.append({
            'src_ip': flow_data['src_ip'],
            'dst_ip': flow_data['dst_ip'],
            'src_port': flow_data['src_port'],
            'dst_port': flow_data['dst_port'],
            'protocol': flow_data['protocol'],
            'timestamp': start_time
        })
    
    return metadata_list


def _parse_http_request(payload_text):
    """
    –ü–∞—Ä—Å–∏—Ç HTTP –∑–∞–ø—Ä–æ—Å –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –ø–æ–ª—è–º–∏ –∑–∞–ø—Ä–æ—Å–∞.
    """
    http_info = {
        "request_line": "",
        "method": "",
        "path": "",
        "http_version": "",
        "headers": {},
        "body": "",
        "user_agent": "",
        "content_type": "",
        "content_length": "",
        "host": "",
        "cookie": "",
        "accept": "",
        "accept_language": "",
        "accept_encoding": "",
        "origin": "",
        "referer": "",
        "connection": "",
        "upgrade_insecure_requests": ""
    }
    
    if not payload_text:
        return http_info
    
    try:
        lines = payload_text.split('\n')
        if not lines:
            return http_info
        
        # –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - Request Line
        first_line = lines[0].strip()
        if first_line:
            http_info["request_line"] = first_line
            parts = first_line.split()
            if len(parts) >= 3:
                http_info["method"] = parts[0]
                http_info["path"] = parts[1]
                http_info["http_version"] = parts[2]
        
        # –ü–∞—Ä—Å–∏–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
        body_start = -1
        for i, line in enumerate(lines[1:], 1):
            line = line.strip()
            if not line:
                body_start = i
                break
            
            if ':' in line:
                key, value = line.split(':', 1)
                key = key.strip().lower()
                value = value.strip()
                http_info["headers"][key] = value
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏
                if key == 'user-agent':
                    http_info["user_agent"] = value
                elif key == 'content-type':
                    http_info["content_type"] = value
                elif key == 'content-length':
                    http_info["content_length"] = value
                elif key == 'host':
                    http_info["host"] = value
                elif key == 'cookie':
                    http_info["cookie"] = value
                elif key == 'accept':
                    http_info["accept"] = value
                elif key == 'accept-language':
                    http_info["accept_language"] = value
                elif key == 'accept-encoding':
                    http_info["accept_encoding"] = value
                elif key == 'origin':
                    http_info["origin"] = value
                elif key == 'referer':
                    http_info["referer"] = value
                elif key == 'connection':
                    http_info["connection"] = value
                elif key == 'upgrade-insecure-requests':
                    http_info["upgrade_insecure_requests"] = value
        
        # –¢–µ–ª–æ –∑–∞–ø—Ä–æ—Å–∞
        if body_start > 0 and body_start < len(lines):
            http_info["body"] = '\n'.join(lines[body_start:]).strip()
    
    except Exception as e:
        pass  # –ï—Å–ª–∏ –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    
    return http_info


def _extract_packets(pcap_file, output_json="data/packets.json", max_payload_bytes=4096):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø–∞–∫–µ—Ç–æ–≤ –∏–∑ PCAP/PCAPNG –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –Ω–∞ –¥–∞—à–±–æ—Ä–¥–µ.
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ JSON.
    """
    from scapy.all import rdpcap, IP, TCP, UDP, ICMP, Raw
    from feature_extractor import _get_protocol_name, _get_ports
    from io import StringIO
    import contextlib
    from datetime import datetime

    packets = rdpcap(pcap_file)
    packet_rows = []

    for idx, packet in enumerate(packets):
        ts = float(packet.time)
        src_ip = packet[IP].src if packet.haslayer(IP) else ""
        dst_ip = packet[IP].dst if packet.haslayer(IP) else ""
        protocol_name = _get_protocol_name(packet)
        src_port, dst_port = _get_ports(packet)
        raw_bytes = bytes(packet)
        payload_bytes = raw_bytes[:max_payload_bytes]

        # –ü–æ–ª–Ω—ã–π –≤—ã–≤–æ–¥ –ø–∞–∫–µ—Ç–∞ (–∫–∞–∫ –≤ scapy.show) ‚Äî —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –æ—à–∏–±–æ–∫
        details = ""
        with contextlib.redirect_stdout(StringIO()) as buf:
            try:
                packet.show()
                details = buf.getvalue()
            except Exception:
                details = packet.summary() if hasattr(packet, "summary") else ""

        # –ü–æ–ø—ã—Ç–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª–µ–∑–Ω—É—é –Ω–∞–≥—Ä—É–∑–∫—É –≤ —Ç–µ–∫—Å—Ç
        readable_payload = ""
        http_info = {}
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º TCP payload –µ—Å–ª–∏ –µ—Å—Ç—å
        if packet.haslayer(Raw):
            try:
                tcp_payload = packet[Raw].load
                readable_payload = tcp_payload.decode("utf-8", errors="replace")
                # –ü–∞—Ä—Å–∏–º HTTP –µ—Å–ª–∏ —ç—Ç–æ HTTP –∑–∞–ø—Ä–æ—Å
                if readable_payload.startswith(('GET ', 'POST ', 'PUT ', 'DELETE ', 'HEAD ', 'OPTIONS ', 'PATCH ')):
                    http_info = _parse_http_request(readable_payload)
            except Exception:
                pass
        
        if not readable_payload and payload_bytes:
            try:
                readable_payload = payload_bytes.decode("utf-8", errors="replace")
                if readable_payload.startswith(('GET ', 'POST ', 'PUT ', 'DELETE ', 'HEAD ', 'OPTIONS ', 'PATCH ')):
                    http_info = _parse_http_request(readable_payload)
            except Exception:
                readable_payload = ""

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤—Ä–µ–º—è –≤ —á–∏—Ç–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç
        try:
            dt = datetime.fromtimestamp(ts)
            time_formatted = dt.strftime("%d-%m-%Y %H:%M")
        except:
            time_formatted = str(ts)

        # –ì–æ—Ç–æ–≤–∏–º HTML-–≤–µ—Ä—Å–∏—é –≤ —Ñ–æ—Ä–º–∞—Ç–µ –∫–∞–∫ –Ω–∞ —Ñ–æ—Ç–æ
        if http_info and http_info.get("request_line"):
            # HTTP –∑–∞–ø—Ä–æ—Å - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –≤ –∫—Ä–∞—Å–∏–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
            details_html_parts = [
                '<div style="background:#fff; color:#333; padding:20px; border-radius:8px; font-family:monospace; border:1px solid #e9ecef;">',
                '<div style="margin-bottom:20px;">',
                '<h3 style="color:#667eea; margin:0 0 15px 0; font-size:1.1em;">Request information</h3>',
                f'<div style="margin-bottom:8px;"><span style="color:#666; font-weight:600;">Request id:</span> <span style="color:#333;">{idx}</span></div>',
                f'<div style="margin-bottom:8px;"><span style="color:#666; font-weight:600;">Request time:</span> <span style="color:#333;">{time_formatted}</span></div>',
                f'<div style="margin-bottom:8px;"><span style="color:#666; font-weight:600;">From:</span> <span style="color:#333;">{html.escape(src_ip)}</span></div>',
                f'<div style="margin-bottom:8px;"><span style="color:#666; font-weight:600;">To:</span> <span style="color:#333;">{html.escape(dst_ip)}</span></div>',
                f'<div style="margin-bottom:8px;"><span style="color:#666; font-weight:600;">Protocol:</span> <span style="color:#333;">{html.escape(protocol_name)}</span></div>',
                f'<div style="margin-bottom:8px;"><span style="color:#666; font-weight:600;">Port:</span> <span style="color:#333;">{dst_port}</span></div>',
                f'<div style="margin-bottom:8px;"><span style="color:#666; font-weight:600;">Payload length:</span> <span style="color:#333;">{len(packet)} bytes</span></div>',
                '</div>',
                '<div style="border-top:1px solid #e9ecef; padding-top:20px; margin-top:20px;">',
                '<h3 style="color:#667eea; margin:0 0 15px 0; font-size:1.1em;">Payload</h3>',
            ]
            
            # Request Line
            if http_info.get("request_line"):
                details_html_parts.append(f'<div style="margin-bottom:8px;"><span style="color:#666; font-weight:600;">Request Line:</span> <span style="color:#333;">{html.escape(http_info["request_line"])}</span></div>')
            
            # Headers
            if http_info.get("host"):
                details_html_parts.append(f'<div style="margin-bottom:8px;"><span style="color:#666; font-weight:600;">Host:</span> <span style="color:#333;">{html.escape(http_info["host"])}</span></div>')
            if http_info.get("user_agent"):
                details_html_parts.append(f'<div style="margin-bottom:8px;"><span style="color:#666; font-weight:600;">User-Agent:</span> <span style="color:#333;">{html.escape(http_info["user_agent"])}</span></div>')
            if http_info.get("accept"):
                details_html_parts.append(f'<div style="margin-bottom:8px;"><span style="color:#666; font-weight:600;">Accept:</span> <span style="color:#333;">{html.escape(http_info["accept"])}</span></div>')
            if http_info.get("accept_language"):
                details_html_parts.append(f'<div style="margin-bottom:8px;"><span style="color:#666; font-weight:600;">Accept-Language:</span> <span style="color:#333;">{html.escape(http_info["accept_language"])}</span></div>')
            if http_info.get("accept_encoding"):
                details_html_parts.append(f'<div style="margin-bottom:8px;"><span style="color:#666; font-weight:600;">Accept-Encoding:</span> <span style="color:#333;">{html.escape(http_info["accept_encoding"])}</span></div>')
            if http_info.get("content_type"):
                details_html_parts.append(f'<div style="margin-bottom:8px;"><span style="color:#666; font-weight:600;">Content-Type:</span> <span style="color:#333;">{html.escape(http_info["content_type"])}</span></div>')
            if http_info.get("content_length"):
                details_html_parts.append(f'<div style="margin-bottom:8px;"><span style="color:#666; font-weight:600;">Content-Length:</span> <span style="color:#333;">{html.escape(http_info["content_length"])}</span></div>')
            if http_info.get("origin"):
                details_html_parts.append(f'<div style="margin-bottom:8px;"><span style="color:#666; font-weight:600;">Origin:</span> <span style="color:#333;">{html.escape(http_info["origin"])}</span></div>')
            if http_info.get("connection"):
                details_html_parts.append(f'<div style="margin-bottom:8px;"><span style="color:#666; font-weight:600;">Connection:</span> <span style="color:#333;">{html.escape(http_info["connection"])}</span></div>')
            if http_info.get("referer"):
                details_html_parts.append(f'<div style="margin-bottom:8px;"><span style="color:#666; font-weight:600;">Referer:</span> <span style="color:#333;">{html.escape(http_info["referer"])}</span></div>')
            if http_info.get("cookie"):
                details_html_parts.append(f'<div style="margin-bottom:8px;"><span style="color:#666; font-weight:600;">Cookie:</span> <span style="color:#333;">{html.escape(http_info["cookie"])}</span></div>')
            if http_info.get("upgrade_insecure_requests"):
                details_html_parts.append(f'<div style="margin-bottom:8px;"><span style="color:#666; font-weight:600;">Upgrade-Insecure-Requests:</span> <span style="color:#333;">{html.escape(http_info["upgrade_insecure_requests"])}</span></div>')
            
            # Body
            if http_info.get("body"):
                details_html_parts.append(f'<div style="margin-top:15px;"><span style="color:#666; font-weight:600;">Body:</span></div>')
                details_html_parts.append(f'<pre style="background:#f8f9fa; padding:10px; border-radius:4px; margin-top:5px; overflow:auto; color:#333; border:1px solid #e9ecef;">{html.escape(http_info["body"])}</pre>')
            
            details_html_parts.append('</div></div>')
            details_html = "\n".join(details_html_parts)
        else:
            # –ù–µ HTTP - –æ–±—ã—á–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
            details_html_parts = [
                f"<strong>Timestamp:</strong> {ts}",
                f"<strong>Source:</strong> {html.escape(src_ip)}:{src_port}",
                f"<strong>Destination:</strong> {html.escape(dst_ip)}:{dst_port}",
                f"<strong>Protocol:</strong> {protocol_name}",
                f"<strong>Port:</strong> {dst_port}",
                f"<strong>Length:</strong> {len(packet)}",
                "<hr>",
                "<strong>Summary</strong><br>",
                f"<pre style='white-space:pre-wrap;margin:0;'>{html.escape(packet.summary() if hasattr(packet, 'summary') else '')}</pre>",
            ]

            if readable_payload:
                details_html_parts.extend([
                    "<hr>",
                    "<strong>Payload (text)</strong><br>",
                    f"<pre style='white-space:pre-wrap;margin:0;'>{html.escape(readable_payload)}</pre>",
                ])

            if payload_bytes:
                details_html_parts.extend([
                    "<hr>",
                    "<strong>Payload (hex, truncated)</strong><br>",
                    f"<pre style='white-space:pre-wrap;margin:0;'>{payload_bytes.hex()}</pre>",
                ])

            if details:
                details_html_parts.extend([
                    "<hr>",
                    "<strong>Scapy details</strong><br>",
                    f"<pre style='white-space:pre-wrap;margin:0;'>{html.escape(details)}</pre>",
                ])

            details_html = "\n".join(details_html_parts)

        packet_rows.append({
            "id": idx,
            "timestamp": ts,
            "time_formatted": time_formatted,
            "src_ip": src_ip,
            "dst_ip": dst_ip,
            "src_port": src_port,
            "dst_port": dst_port,
            "protocol": protocol_name,
            "length": len(packet),
            "summary": packet.summary() if hasattr(packet, "summary") else "",
            "payload_hex": payload_bytes.hex(),
            "payload_hex_full": raw_bytes.hex(),
            "details": details,
            "readable_payload": readable_payload,
            "details_html": details_html,
            "http_info": http_info
        })

    output_dir = os.path.dirname(output_json)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir, exist_ok=True)

    with open(output_json, "w", encoding="utf-8") as f:
        json.dump(packet_rows, f, ensure_ascii=False)

    return packet_rows


def _determine_alert_level(anomaly_score, packet_count, rst_count, syn_count):
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —É—Ä–æ–≤–µ–Ω—å –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏ –∞–Ω–æ–º–∞–ª–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
    
    Args:
        anomaly_score: –û—Ü–µ–Ω–∫–∞ –∞–Ω–æ–º–∞–ª–∏–∏ (–º–µ–Ω—å—à–µ 0 = –∞–Ω–æ–º–∞–ª–∏—è)
        packet_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤ –≤ –ø–æ—Ç–æ–∫–µ
        rst_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ RST —Ñ–ª–∞–≥–æ–≤
        syn_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ SYN —Ñ–ª–∞–≥–æ–≤
    
    Returns:
        str: –£—Ä–æ–≤–µ–Ω—å –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏ (LOW, MEDIUM, HIGH, CRITICAL)
    """
    # –ß–µ–º –º–µ–Ω—å—à–µ anomaly_score, —Ç–µ–º –≤—ã—à–µ –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º score: –æ–±—ã—á–Ω–æ –æ—Ç -0.5 –¥–æ 0.5, –≥–¥–µ –º–µ–Ω—å—à–µ = —Ö—É–∂–µ
    score_normalized = abs(anomaly_score) if anomaly_score < 0 else 0
    
    # –ö—Ä–∏—Ç–µ—Ä–∏–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —É—Ä–æ–≤–Ω—è
    if score_normalized > 0.3 or (packet_count > 1000 and rst_count > 10):
        return "CRITICAL"
    elif score_normalized > 0.2 or (packet_count > 500 and syn_count > 50):
        return "HIGH"
    elif score_normalized > 0.1 or packet_count > 100:
        return "MEDIUM"
    elif score_normalized > 0:
        return "LOW"
    else:
        return "NORMAL"


def analyze_traffic(pcap_file, model_path=None, output_csv="data/analysis_results.csv"):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç PCAP —Ñ–∞–π–ª –∏ –æ–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –∞–Ω–æ–º–∞–ª–∏–∏.
    
    Args:
        pcap_file: –ü—É—Ç—å –∫ PCAP —Ñ–∞–π–ª—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        model_path: –ü—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π)
        output_csv: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    
    Returns:
        dict: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞
    """
    if not os.path.exists(pcap_file):
        raise FileNotFoundError(f"PCAP —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {pcap_file}")
    
    print("=" * 60)
    print("üîç –ê–Ω–∞–ª–∏–∑ —Å–µ—Ç–µ–≤–æ–≥–æ —Ç—Ä–∞—Ñ–∏–∫–∞")
    print("=" * 60)
    print(f"üì¶ PCAP —Ñ–∞–π–ª: {pcap_file}")
    
    # –®–∞–≥ 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    print("\nüìä –®–∞–≥ 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ —Ç—Ä–∞—Ñ–∏–∫–∞...")
    temp_features_file = "data/temp_features.csv"
    features_df = extract_features_from_pcap(pcap_file, temp_features_file, is_anomaly=0)
    
    if len(features_df) == 0:
        print("‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ PCAP —Ñ–∞–π–ª–∞")
        return None
    
    # –®–∞–≥ 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤
    print("\nüìã –®–∞–≥ 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤...")
    metadata_list = _extract_flow_metadata(pcap_file)
    
    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –ø–æ –∫–ª—é—á—É –ø–æ—Ç–æ–∫–∞
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–º–±–∏–Ω–∞—Ü–∏—é –ø–æ—Ä—Ç–æ–≤ –∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –∫–∞–∫ –∫–ª—é—á
    metadata_dict = {}
    for meta in metadata_list:
        key = (meta['src_port'], meta['dst_port'], meta['protocol'])
        # –ï—Å–ª–∏ –∫–ª—é—á —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π (–æ–Ω–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏ –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏)
        if key not in metadata_dict:
            metadata_dict[key] = meta
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–æ—Ç–æ–∫–æ–≤
    if len(metadata_list) != len(features_df):
        print(f"‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç ({len(metadata_list)} vs {len(features_df)})")
        print(f"   –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º –ø–æ—Ç–æ–∫–æ–≤")
    
    # –®–∞–≥ 3: –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π
    print("\nü§ñ –®–∞–≥ 3: –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π...")
    
    if model_path is None or not os.path.exists(model_path):
        print("‚ö†Ô∏è  –ú–æ–¥–µ–ª—å –Ω–µ —É–∫–∞–∑–∞–Ω–∞ –∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–æ–≤–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞.")
        # –ë–∞–∑–æ–≤–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π
        anomaly_scores = []
        is_anomaly_list = []
        
        for idx, row in features_df.iterrows():
            # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –º–Ω–æ–≥–æ RST, –º–Ω–æ–≥–æ SYN, –Ω–µ–æ–±—ã—á–Ω—ã–µ –ø–æ—Ä—Ç—ã
            score = 0.0
            if row['rst_count'] > 5:
                score -= 0.3
            if row['syn_count'] > 20 and row['packet_count'] < 10:
                score -= 0.2
            if row['packet_count'] > 1000:
                score -= 0.2
            if row['dst_port'] < 1024 and row['src_port'] > 49152:
                score -= 0.1
            
            anomaly_scores.append(score)
            is_anomaly_list.append(1 if score < -0.1 else 0)
    else:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        print(f"   –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {model_path}")
        detector = AnomalyDetector()
        detector.load_model(model_path)
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ –æ—Ü–µ–Ω–∫–∏
        predictions = detector.predict(features_df)
        anomaly_scores = detector.predict_anomaly_scores(features_df)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: -1 = –∞–Ω–æ–º–∞–ª–∏—è, 1 = –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π
        is_anomaly_list = (predictions == -1).astype(int).tolist()
        # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º scores –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ (–º–µ–Ω—å—à–µ = —Ö—É–∂–µ)
        anomaly_scores = (-anomaly_scores).tolist()
    
    # –®–∞–≥ 4: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\nüíæ –®–∞–≥ 4: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
    
    results = []
    for idx, row in features_df.iterrows():
        anomaly_score = anomaly_scores[idx] if idx < len(anomaly_scores) else 0.0
        is_anomaly = is_anomaly_list[idx] if idx < len(is_anomaly_list) else 0
        
        # –ù–∞—Ö–æ–¥–∏–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø–æ –∫–ª—é—á—É –ø–æ—Ç–æ–∫–∞
        flow_key = (row['src_port'], row['dst_port'], row['protocol'])
        
        if flow_key in metadata_dict:
            metadata = metadata_dict[flow_key]
        elif idx < len(metadata_list):
            # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–Ω–¥–µ–∫—Å, –µ—Å–ª–∏ –µ—Å—Ç—å
            metadata = metadata_list[idx]
        else:
            # –ï—Å–ª–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ features_df
            metadata = {
                'src_ip': '0.0.0.0',  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                'dst_ip': '0.0.0.0',
                'src_port': row['src_port'],
                'dst_port': row['dst_port'],
                'protocol': row['protocol'],
                'timestamp': 0.0
            }
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏
        alert_level = _determine_alert_level(
            anomaly_score,
            row['packet_count'],
            row['rst_count'],
            row['syn_count']
        )

        result_row = {
            'timestamp': metadata['timestamp'],
            'src_ip': metadata['src_ip'],
            'dst_ip': metadata['dst_ip'],
            'src_port': metadata['src_port'],
            'dst_port': metadata['dst_port'],
            'protocol': metadata['protocol'],
            'packet_count': row['packet_count'],
            'anomaly_score': anomaly_score,
            'is_anomaly': is_anomaly,
            'alert_level': alert_level
        }
        
        results.append(result_row)
    
    # –°–æ–∑–¥–∞–µ–º DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    results_df = pd.DataFrame(results)
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    output_dir = os.path.dirname(output_csv)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir, exist_ok=True)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    results_df.to_csv(output_csv, index=False)
    print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_csv}")
    
    # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    if os.path.exists(temp_features_file):
        os.remove(temp_features_file)
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ –ø–∞–∫–µ—Ç–æ–≤ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –≤ –¥–∞—à–±–æ—Ä–¥–µ
    try:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º packets.json –≤ —Ç—É –∂–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, —á—Ç–æ –∏ output_csv
        packets_json_path = os.path.join(output_dir, "packets.json") if output_dir else "data/packets.json"
        _extract_packets(pcap_file, output_json=packets_json_path)
        print(f"üì¶ –°–ø–∏—Å–æ–∫ –ø–∞–∫–µ—Ç–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {packets_json_path}")
    except Exception as e:
        print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø–∞–∫–µ—Ç–æ–≤: {e}")
    
    # –®–∞–≥ 5: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
    print("\nüìä –®–∞–≥ 5: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞...")
    stats = _generate_report(results_df, output_csv)
    
    return stats


def _generate_report(results_df, output_csv):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –æ–± –∞–Ω–∞–ª–∏–∑–µ —Ç—Ä–∞—Ñ–∏–∫–∞.
    
    Args:
        results_df: DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        output_csv: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    
    Returns:
        dict: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞
    """
    total_flows = len(results_df)
    anomalies = results_df[results_df['is_anomaly'] == 1]
    num_anomalies = len(anomalies)
    anomaly_percentage = (num_anomalies / total_flows * 100) if total_flows > 0 else 0
    
    # –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ IP –∞–¥—Ä–µ—Å–∞ (IP, –∫–æ—Ç–æ—Ä—ã–µ —É—á–∞—Å—Ç–≤—É—é—Ç –≤ –∞–Ω–æ–º–∞–ª–∏—è—Ö)
    suspicious_ips = set()
    if num_anomalies > 0:
        suspicious_ips.update(anomalies['src_ip'].unique())
        suspicious_ips.update(anomalies['dst_ip'].unique())
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —É—Ä–æ–≤–Ω—è–º –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏
    alert_levels = results_df['alert_level'].value_counts().to_dict()
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –∞–Ω–æ–º–∞–ª–∏–π (–Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
    anomaly_stats = {}
    if num_anomalies > 0:
        anomaly_stats = {
            'high_rst_count': len(anomalies[anomalies['packet_count'] > 0]),  # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            'high_packet_count': len(anomalies[anomalies['packet_count'] > 500]),
            'suspicious_ports': len(anomalies[(anomalies['dst_port'] < 1024) & (anomalies['src_port'] > 49152)])
        }
    
    # –í—ã–≤–æ–¥–∏–º –æ—Ç—á–µ—Ç
    print("\n" + "=" * 60)
    print("üìà –û–¢–ß–ï–¢ –û–ë –ê–ù–ê–õ–ò–ó–ï –¢–†–ê–§–ò–ö–ê")
    print("=" * 60)
    print(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤:     {total_flows}")
    print(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∞–Ω–æ–º–∞–ª–∏–π:           {num_anomalies} ({anomaly_percentage:.2f}%)")
    print(f"–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö IP –∞–¥—Ä–µ—Å–æ–≤:    {len(suspicious_ips)}")
    
    if suspicious_ips:
        print(f"\nüî¥ –¢–æ–ø-10 –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö IP –∞–¥—Ä–µ—Å–æ–≤:")
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–Ω–æ–º–∞–ª–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ IP
        ip_counts = {}
        for _, row in anomalies.iterrows():
            for ip in [row['src_ip'], row['dst_ip']]:
                ip_counts[ip] = ip_counts.get(ip, 0) + 1
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∞–Ω–æ–º–∞–ª–∏–π
        sorted_ips = sorted(ip_counts.items(), key=lambda x: x[1], reverse=True)[:10]
        for ip, count in sorted_ips:
            print(f"   {ip:15s} - {count} –∞–Ω–æ–º–∞–ª–∏–π")
    
    print(f"\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —É—Ä–æ–≤–Ω—è–º –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏:")
    for level in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW', 'NORMAL']:
        count = alert_levels.get(level, 0)
        if count > 0:
            print(f"   {level:10s}: {count:4d} –ø–æ—Ç–æ–∫–æ–≤")
    
    if anomaly_stats:
        print(f"\nüîç –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –∞–Ω–æ–º–∞–ª–∏–π:")
        print(f"   –ü–æ—Ç–æ–∫–æ–≤ —Å –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø–∞–∫–µ—Ç–æ–≤: {anomaly_stats.get('high_packet_count', 0)}")
        print(f"   –ü–æ—Ç–æ–∫–æ–≤ —Å –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–º–∏ –ø–æ—Ä—Ç–∞–º–∏:     {anomaly_stats.get('suspicious_ports', 0)}")
    
    print("=" * 60)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ª–æ–≤–∞—Ä—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    stats = {
        'total_flows': total_flows,
        'num_anomalies': num_anomalies,
        'anomaly_percentage': anomaly_percentage,
        'suspicious_ips': list(suspicious_ips),
        'alert_levels': alert_levels,
        'anomaly_stats': anomaly_stats,
        'output_file': output_csv
    }
    
    return stats


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    import sys
    
    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python traffic_analyzer.py <pcap_file> [model_path] [output_csv]")
        print("\n–ü—Ä–∏–º–µ—Ä—ã:")
        print("  python traffic_analyzer.py data/mixed_traffic.pcap")
        print("  python traffic_analyzer.py data/mixed_traffic.pcap models/anomaly_detector.pkl")
        print("  python traffic_analyzer.py data/mixed_traffic.pcap models/anomaly_detector.pkl data/results.csv")
        sys.exit(1)
    
    pcap_file = sys.argv[1]
    model_path = sys.argv[2] if len(sys.argv) > 2 else None
    output_csv = sys.argv[3] if len(sys.argv) > 3 else "data/analysis_results.csv"
    
    stats = analyze_traffic(pcap_file, model_path, output_csv)
    
    if stats:
        print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        print(f"üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {stats['output_file']}")
